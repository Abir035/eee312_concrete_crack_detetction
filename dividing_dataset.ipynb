{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dividing_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EYIi-AvczXs"
      },
      "source": [
        "### **Mounting google drive with our colab notebooks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljmY55G_ShbX",
        "outputId": "9abe1b90-fd43-4488-f243-751aa4105050"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf6HTTl2dDws"
      },
      "source": [
        "### **Importing Necessary Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0NSh_gSLDWF"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import glob, os, shutil,random\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb6c2KGHdO8c"
      },
      "source": [
        "### **Defining our preferred image size**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQxJaxFpN-Q8"
      },
      "source": [
        "IMG_SIZE = (224,224)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jXkhBEO2uPh"
      },
      "source": [
        "### **Finding any irregularity in our dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtA6ah6u6VVR"
      },
      "source": [
        "dim = IMG_SIZE\n",
        "count = 0\n",
        "dirpath = '/content/drive/MyDrive/datasets/Train_val_test/test/Negative/'\n",
        "os.chdir(dirpath)\n",
        "\n",
        "filenames = os.listdir(dirpath) #random.sample(os.listdir(dirpath),7190)\n",
        "\n",
        "for fname in filenames:\n",
        "  print(count,fname)\n",
        "  img = cv2.imread(fname)\n",
        "  img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "  data_dir = '/content/drive/MyDrive/datasets/Train_val_test/reshaped_dataset/test/neg/'\n",
        "\n",
        "  name = data_dir + fname\n",
        "  cv2.imwrite(name, img)\n",
        "  count += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9niEJ1V_fjA"
      },
      "source": [
        "removed files:\n",
        "\n",
        "15890_1.jpg\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rEwpP0v8dMu"
      },
      "source": [
        "\n",
        "# verifying if the file is really corrupted\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/drive/MyDrive/datasets/Train_val_test/val/Positive/15890_1.jpg')\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWXSqNnf-Wr_",
        "outputId": "379d8bc9-b44d-4488-dd6b-0879fb3dfbe9"
      },
      "source": [
        "\n",
        "\n",
        "#removing the corrupted files\n",
        "import os\n",
        "if os.path.exists('/content/drive/MyDrive/datasets/Train_val_test/val/Positive/15890_1.jpg'):\n",
        "  os.remove('/content/drive/MyDrive/datasets/Train_val_test/val/Positive/15890_1.jpg')\n",
        "  print('removed')\n",
        "else:\n",
        "  print(\"The file does not exist\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "removed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRL0X-0GdW-N"
      },
      "source": [
        "### **Dividing and resizing the dataset**\n",
        "Only the division and resizing of SDNET is shown. Our Mendeley Data was divided using a similar code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPYdfMwsw9cE"
      },
      "source": [
        "dim = IMG_SIZE\n",
        "count = 0\n",
        "dirpath = '/content/gdrive/MyDrive/Dataset/Train_val_test/Cracked/'\n",
        "os.chdir(dirpath)\n",
        "\n",
        "filenames = os.listdir(dirpath) \n",
        "\n",
        "for fname in filenames:\n",
        "  print(count,fname)\n",
        "  img = cv2.imread(fname)\n",
        "  img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "  data_dir = '/content/gdrive/MyDrive/Dataset/Train_val_test/Reshaped_sdnet/pos/'\n",
        "\n",
        "  name = data_dir + fname\n",
        "  cv2.imwrite(name, img)\n",
        "  count += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCnsaLr5ymIP"
      },
      "source": [
        "dim = IMG_SIZE\n",
        "count = 0\n",
        "dirpath = '/content/gdrive/MyDrive/Dataset/Train_val_test/Negative/'\n",
        "os.chdir(dirpath)\n",
        "\n",
        "filenames = os.listdir(dirpath)\n",
        "\n",
        "for fname in filenames:\n",
        "  print(count,fname)\n",
        "  img = cv2.imread(fname)\n",
        "  img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "  data_dir = '/content/gdrive/MyDrive/Dataset/Train_val_test/Reshaped_sdnet/neg/'\n",
        "\n",
        "  name = data_dir + fname\n",
        "  cv2.imwrite(name, img)\n",
        "  count += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmdLIJGYFJ6L"
      },
      "source": [
        "import shutil, random, os\n",
        "\n",
        "dirpath = '/content/gdrive/MyDrive/Dataset/Train_val_test/Reshaped_sdnet/pos/'\n",
        "\n",
        "filenames = random.sample(os.listdir(dirpath), 3851)\n",
        "count = 0\n",
        "for fname in filenames:\n",
        "    src = '/content/gdrive/MyDrive/Dataset/Train_val_test/Reshaped_sdnet/pos/' + fname\n",
        "    #img = cv.imread(src)\n",
        "    #norm_img = np.zeros((720,720))\n",
        "    #final_img = cv.normalize(img,  norm_img, 0, 255, cv.NORM_MINMAX)\n",
        "    \n",
        "    if count < 2310:\n",
        "      dest = '/content/gdrive/MyDrive/Dataset/Train_val_test/reshaped_dataset/train/pos/' + fname\n",
        "    elif count < 3081 :\n",
        "      dest = '/content/gdrive/MyDrive/Dataset/Train_val_test/reshaped_dataset/val/pos/' + fname\n",
        "    else:\n",
        "      dest = '/content/gdrive/MyDrive/Dataset/Train_val_test/reshaped_dataset/test/pos/' + fname\n",
        "\n",
        "    #cv.imwrite(dest, final_img)\n",
        "    shutil.copy(src, dest)\n",
        "    \n",
        "    print(count)\n",
        "    count += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMXmZCykFM7R"
      },
      "source": [
        "import shutil, random, os\n",
        "\n",
        "dirpath = '/content/gdrive/MyDrive/Dataset/Train_val_test/Reshaped_sdnet/neg/'\n",
        "\n",
        "filenames = random.sample(os.listdir(dirpath), 3851)\n",
        "count = 0\n",
        "for fname in filenames:\n",
        "    src = '/content/gdrive/MyDrive/Dataset/Train_val_test/Reshaped_sdnet/neg/' + fname\n",
        "    #img = cv.imread(src)\n",
        "    #norm_img = np.zeros((720,720))\n",
        "    #final_img = cv.normalize(img,  norm_img, 0, 255, cv.NORM_MINMAX)\n",
        "    \n",
        "    if count < 2310 :\n",
        "      dest = '/content/gdrive/MyDrive/Dataset/Train_val_test/reshaped_dataset/train/neg/' + fname\n",
        "    elif count < 3081:\n",
        "      dest = '/content/gdrive/MyDrive/Dataset/Train_val_test/reshaped_dataset/val/neg/' + fname\n",
        "    else:\n",
        "      dest = '/content/gdrive/MyDrive/Dataset/Train_val_test/reshaped_dataset/test/neg/' + fname\n",
        "\n",
        "    #cv.imwrite(dest, final_img)\n",
        "    shutil.copy(src, dest)\n",
        "    \n",
        "    print(count)\n",
        "    count += 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}