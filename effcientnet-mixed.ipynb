{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# IMPORTS\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport glob, os, shutil,random\nimport tensorflow as tf\nimport cv2\n\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# IMPORTS\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Flatten, Dropout, Dense, BatchNormalization, Input, Lambda, Activation, Conv2D, MaxPooling2D, Reshape, Bidirectional, TimeDistributed, GRU\nfrom tensorflow.keras.layers import concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, CSVLogger, EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DIRECTORIES\nDIRECTORY = '/content/drive/MyDrive/Dataset/Datasets_to_use/Mixed_Dataset/'\nTRAIN_DIR = os.path.join(DIRECTORY, 'train')\nVAL_DIR = os.path.join(DIRECTORY, 'val')\nTEST_DIR = os.path.join(DIRECTORY, 'test')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# HYPERPARAMETERS\nlearning_rate = 0.0001\nBATCH_SIZE = 32\nIMG_SIZE = (224,224)\nINPUT_SHAPE = (224, 224, 3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ASSIGNING DATASET TO VARIABLE\nTRAIN_IT = image_dataset_from_directory(TRAIN_DIR, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE)\nVAL_IT = image_dataset_from_directory(VAL_DIR, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE)\nTEST_IT = image_dataset_from_directory(TEST_DIR, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATA AUGMENTATION\nDATA_AUG = tf.keras.Sequential([ tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal_and_vertical'),\n  tf.keras.layers.experimental.preprocessing.RandomRotation(0.3) ])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATA BEFORE AUGMENTATION\nCLASSES = TRAIN_IT.class_names\n\nplt.figure(figsize=(8, 8))\nfor images, labels in TRAIN_IT.take(1):\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(CLASSES[labels[i]])\n    plt.axis(\"off\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATA AFTER AUGMENTATION\nfor image, _ in TRAIN_IT.take(1):\n  plt.figure(figsize=(8, 8))\n  first_image = image[0]\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    aug_img = DATA_AUG(tf.expand_dims(first_image, 0))\n    plt.imshow(aug_img[0] / 255)\n    plt.axis('off')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\n\nTRAIN_IT = TRAIN_IT.prefetch(buffer_size=AUTOTUNE)\nVAL_IT = VAL_IT.prefetch(buffer_size=AUTOTUNE)\nTEST_IT = TEST_IT.prefetch(buffer_size=AUTOTUNE)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INITIAL_MODEL = tf.keras.applications.efficientnet.EfficientNetB0(input_shape= INPUT_SHAPE, include_top=False, weights='imagenet')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INITIAL_MODEL.trainable = False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INITIAL_MODEL.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_layer = tf.keras.layers.Dense(1,activation='sigmoid')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input = tf.keras.Input(shape= INPUT_SHAPE)\nx = DATA_AUG(input)\nx = tf.keras.applications.efficientnet.preprocess_input(input)\nx = INITIAL_MODEL(x, training=False)\nx = tf.keras.layers.GlobalAveragePooling2D() (x)\nx = tf.keras.layers.Dropout(0.3)(x)\noutput = pred_layer(x)\nmodel = tf.keras.Model(input, output)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate),loss=tf.keras.losses.BinaryCrossentropy(from_logits= False),\n              metrics=['accuracy'#,'Precision', 'Recall'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nhistory = model.fit(TRAIN_IT, epochs=epochs, validation_data=VAL_IT)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INITIAL_MODEL.trainable = True","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fine-tune from this layer onwards\nfine_tune_at = 100\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in INITIAL_MODEL.layers[:fine_tune_at]:\n  layer.trainable =  False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits= False), optimizer = tf.keras.optimizers.RMSprop(lr=learning_rate/10),\n              metrics=['accuracy','Precision','Recall'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fine_tune_epochs = 10\ntotal_epochs =  epochs + fine_tune_epochs\n\nhistory_fine = model.fit(TRAIN_IT,\n                         epochs=total_epochs,\n                         initial_epoch=history.epoch[-1],\n                         validation_data=VAL_IT)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc += history_fine.history['accuracy']\nval_acc += history_fine.history['val_accuracy']\n\nloss += history_fine.history['loss']\nval_loss += history_fine.history['val_loss']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.ylim([0.8, 1])\nplt.plot([epochs-1,epochs-1],\n          plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.ylim([0, 1.0])\nplt.plot([epochs-1,epochs-1],\n         plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy, precision, recall = model.evaluate(TEST_IT)\nprint('Test accuracy :', accuracy)\nprint('Test precision :', precision)\nprint('Test recall :', recall)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_score = (2*precision*recall)/(precision+recall)\nprint('F1 Score : ', f1_score)","metadata":{},"execution_count":null,"outputs":[]}]}